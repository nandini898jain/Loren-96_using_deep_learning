{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP1VDpETbK8g"
      },
      "source": [
        "**This is the code of deep ANN to conduct prediction on the multi-scale Lorenz 96.There is no overfitting in the training phase because the final training and testing accuracies are the same. Our code is developed in Keras. It must be noted that unlike RC-ESN (and RNN-LSTM),this ANN is stateless, i.e., there is no hidden variable such as states that tracks temporal evolution.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RftUTcUvVh8a"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install keras\n",
        "!pip install scipy\n",
        "!pip install tensorflow\n",
        "\n",
        "#importing all the required libraries\n",
        "import sys\n",
        "import numpy as np                   \n",
        "import scipy.sparse as sparse\n",
        "from scipy.sparse import linalg\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import RMSprop, SGD, Adagrad, Adadelta\n",
        "#import json\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import genfromtxt\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#load the lorenz 96 data \n",
        "dataf = pd.read_csv('https://github.com/ashesh6810/RCESN_spatio_temporal/blob/74b066667abd252d4d0f18debdc9043f5e9a1e7a/3tier_lorenz_v3.csv?raw=true')\n",
        "data = np.array(dataf)\n",
        "print(np.shape(data))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#defining global variables\n",
        "shift_k = 0\n",
        "#shift_k=int(shift_k)\n",
        "res_params = {\n",
        "             'train_length': 500000,\n",
        "             'predict_length': 2000\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# training the reservoir\n",
        "train = data[shift_k:shift_k+res_params['train_length'],:]\n",
        "label = data[1+shift_k:1+shift_k+res_params['train_length'],:]\n",
        "print('np.shape(train)', np.shape(train))\n",
        "print('np.shape(label)', np.shape(label))\n",
        "print(train)\n",
        "print(label)\n",
        "\n",
        "\n",
        "y_train = label - train\n",
        "x_train = train\n",
        "print('np.shape(y_train)', np.shape(y_train))\n",
        "print('np.shape(x_train)', np.shape(x_train))\n",
        "\n",
        "\n",
        "\n",
        "#building of neural network model\n",
        "#activation function used is tanh\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation='tanh'))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "\n",
        "#compilation of model\n",
        "model.compile(loss='mean_absolute_error', optimizer='SGD', metrics=['mae'])\n",
        "#fitting of the model\n",
        "model.fit(x_train, y_train,batch_size=128, epochs=200, validation_split=0.2)\n",
        "\n",
        "#weights of the network are computed using backpropagation optimized by the stochastic gradient descent\n",
        "model.save_weights(\"./weights_Shift\"+str(shift_k)+\"K\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print ('Read reference state')\n",
        "#reference state contains a reference to the previous time step for further prediction \n",
        "#Load the reference state\n",
        "ref_state = np.transpose(data[shift_k+res_params['train_length']:shift_k+res_params['train_length']+res_params['predict_length'],:])\n",
        "print('np.shape(ref_state)',np.shape(ref_state))\n",
        "\n",
        "train_y = data[1+shift_k:1+shift_k+res_params['train_length'],:]\n",
        "print('np.shape(train_y)',np.shape(train_y))\n",
        "\n",
        "n_dummy = np.shape(ref_state)\n",
        "n_forecasts = 1\n",
        "n_steps =  n_dummy[1]\n",
        "\n",
        "#fore state gives the starting point of time step for forecasting of the model\n",
        "fore_state = np.zeros((n_forecasts*(n_steps+1),8))\n",
        "state = np.zeros(8)\n",
        "state_n = np.zeros((1,8))\n",
        "\n",
        "out0 = np.zeros((8,1))  \n",
        "out1 = np.zeros((8,1))    #tn-1\n",
        "out2 = np.zeros((8,1))    #tn-2\n",
        "out3 = np.zeros((8,1))    #tn-3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the last point from the training as the starting point of forcasting\n",
        "state[:] = train_y[res_params['train_length']-1,:]\n",
        "fore_state[0,:] = state[:]\n",
        "\n",
        "#Adams-Bashforth integration scheme is used here for prediction \n",
        "for j in range(n_steps):\n",
        "    out3=out2\n",
        "    out2=out1\n",
        "    state_n[0,:] = state\n",
        "\n",
        "    out1 = model.predict(state_n,batch_size=1)\n",
        "    if j==0:\n",
        "        out0 = out1          #initial value \n",
        "    if j==1:\n",
        "        out0 = 1.5*out1-0.5*out2       #two step Adams-Bashforth integration scheme\n",
        "     if j>1:\n",
        "        out0 = (23.0/12.0)*out1-(4.0/3.0)*out2+(5.0/12.0)*out3    #three step Adams-Bashforth integration scheme\n",
        "    state[:] = state[:] + out0\n",
        "    fore_state[1*(0)+j+1,:] = state[:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.savetxt('output_ANN'+ 'shift'+str(shift_k)+ 'trainN' + str(res_params['train_length'])+'.csv',fore_state,delimiter=',')\n",
        "np.savetxt('truth_ANN'+ 'shift'+str(shift_k)+ 'trainN' + str(res_params['train_length'])+'.csv',ref_state,delimiter=',')\n",
        "print('done')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oter_g6KbJZv"
      },
      "source": [
        ""
      ]
    }
  ]
}