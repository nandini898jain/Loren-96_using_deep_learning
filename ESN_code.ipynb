{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESN  code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nYNnof7d2Uw"
      },
      "source": [
        "This is the code of deep RC-ESN to conduct prediction on the multiscale lorenz 96 model. The two components of the RC-ESN are an input-to-reservoir layer with weight matrix Win, and a reservoir-to-output layer with weight matrix Wout. A and Win are chosen randomly and are ﬁxed; i.e. they do not change during training or testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SFqGoU_tCDu"
      },
      "source": [
        "\n",
        "!pip install scipy\n",
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "\n",
        "\n",
        "# importing all the required libraries\n",
        "\timport numpy as np\n",
        "\timport scipy.sparse as sparse\n",
        "\tfrom scipy.sparse import linalg\n",
        "\timport pandas as pd\n",
        "\t\n",
        "\n",
        "\t\n",
        "\n",
        "\t# defining the global variables\n",
        "\tshift_k = 0\n",
        "\t\n",
        "\n",
        "\tapprox_res_size = 5000\n",
        "\t\n",
        "\n",
        "\t\n",
        "# model parameters\n",
        "\tmodel_params = {'tau': 0.25,\n",
        "\t                'nstep': 1000,\n",
        "\t                'N': 8,\n",
        "\t                'd': 22}\n",
        "\t\n",
        "# reservoir parameters\n",
        "\tres_params = {'radius':0.1,\n",
        "\t             'degree': 3,\n",
        "\t             'sigma': 0.5,\n",
        "\t             'train_length': 100000,\n",
        "\t             'N': int(np.floor(approx_res_size/model_params['N']) * model_params['N']),\n",
        "\t             'num_inputs': model_params['N'],\n",
        "\t             'predict_length': 2000,\n",
        "\t             'beta': 0.0001\n",
        "\t              }\n",
        "\t\n",
        "\n",
        "\t# The ESN functions for training\n",
        "  # generating reservoir A such that spectral radius has to be less than unity\n",
        "\tdef generate_reservoir(size,radius,degree):\n",
        "\t    sparsity = degree/float(size);\n",
        "\t    A = sparse.rand(size,size,density=sparsity).todense()  # sparsely connected neurons\n",
        "\t    vals = np.linalg.eigvals(A)\n",
        "\t    e = np.max(np.abs(vals))                               # e is the largest eigen value\n",
        "\t    A = (A/e) * radius                     \n",
        "\t    return A\n",
        "\t\n",
        "#computing state matrix of reservoir layer\n",
        "\tdef reservoir_layer(A, Win, input, res_params):\n",
        "\t    states = np.zeros((res_params['N'],res_params['train_length']))    \n",
        "\t    for i in range(res_params['train_length']-1):\n",
        "\t        states[:,i+1] = np.tanh(np.dot(A,states[:,i]) + np.dot(Win,input[:,i]))        # states are calculated using r(t + ∆t) = tanh(Ar(t) + WinX(t))\n",
        "\t    return states\n",
        "\t\n",
        "\n",
        "\t\n",
        "  # Training the reservoir\n",
        "\tdef train_reservoir(res_params, data):\n",
        "\t    A = generate_reservoir(res_params['N'], res_params['radius'], res_params['degree'])        # calling generate_reservoir function\n",
        "\t    q = int(res_params['N']/res_params['num_inputs'])                                          # number of neurons in a layer of reservoir\n",
        "\t    Win = np.zeros((res_params['N'],res_params['num_inputs']))\n",
        "\t    for i in range(res_params['num_inputs']):\n",
        "\t        np.random.seed(seed=i)\n",
        "\t        Win[i*q: (i+1)*q,i] = res_params['sigma'] * (-1 + 2 * np.random.rand(1,q)[0])          # weight matrix Win whose values are drawn from uniform random distribution on [-1,1]\n",
        "\t    states = reservoir_layer(A, Win, data, res_params)                                         # calling reservoir_layer function\n",
        "\t    Wout = train(res_params, states, data)                                                     # calling train function\n",
        "\t    x = states[:,-1]\n",
        "\t    return x, Wout, A, Win\n",
        "\t\n",
        "  # computing trainable matrix Wout\n",
        "\tdef train(res_params,states,data):\n",
        "\t    beta = res_params['beta']\n",
        "\t    idenmat = beta * sparse.identity(res_params['N'])\n",
        "\t    states2 = states.copy()\n",
        "      # nonlinear combination of reservoir state matrix using algorithm T2\n",
        "\t    for j in range(2,np.shape(states2)[0]-2):\n",
        "\t        if (np.mod(j,2)==0):\n",
        "\t            states2[j,:] = (states[j-1,:]*states[j-2,:]).copy()                                  # using algorithm T2,if j>1 is odd\n",
        "\t    U = np.dot(states2,states2.transpose()) + idenmat     \n",
        "\t    Uinv = np.linalg.inv(U)\n",
        "\t    Wout = np.dot(Uinv,np.dot(states2,data.transpose()))                                         # reservoir to output weight matrix\n",
        "\t    return Wout.transpose() \n",
        "\t\n",
        "\n",
        "  # Wout is marching forward in time during prediction (testing) \n",
        "\tdef predict(A, Win, res_params, x, Wout):\n",
        "\t    output = np.zeros((res_params['num_inputs'],res_params['predict_length']))\n",
        "\t    for i in range(res_params['predict_length']):\n",
        "\t        x_aug = x.copy()\n",
        "\t        for j in range(2,np.shape(x_aug)[0]-2):                                   # using algorithm T2,if j>1 is odd\n",
        "\t            if (np.mod(j,2)==0):                       \n",
        "\t                x_aug[j] = (x[j-1]*x[j-2]).copy()           \n",
        "\t        out = np.squeeze(np.asarray(np.dot(Wout,x_aug)))                          # using prediction process equation v(t + ∆t) = Wout˜r(t + ∆t)\n",
        "\t        output[:,i] = out\n",
        "\t        x1 = np.tanh(np.dot(A,x) + np.dot(Win,out))                               # states are getting calculated for further prediction\n",
        "\t        x = np.squeeze(np.asarray(x1))\n",
        "\t    return output, x\n",
        "\t\n",
        " # loading lorenz 96 data\n",
        "dataf = pd.read_csv('https://github.com/ashesh6810/RCESN_spatio_temporal/blob/74b066667abd252d4d0f18debdc9043f5e9a1e7a/3tier_lorenz_v3.csv?raw=true')\n",
        "data = np.transpose(np.array(dataf))\n",
        "\t\n",
        "\n",
        "\t# Train reservoir\n",
        "\tx,Wout,A,Win = train_reservoir(res_params,data[:,shift_k:shift_k+res_params['train_length']])\n",
        "\t\n",
        "\n",
        "\t# Prediction\n",
        "\toutput, _ = predict(A, Win,res_params,x,Wout)\n",
        "\tnp.save('Expansion_2step_back'+'R_size_train_'+str(res_params['train_length'])+'_Rd_'+str(res_params['radius'])+'_Shift_'+str(shift_k)+'.npy',output)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}