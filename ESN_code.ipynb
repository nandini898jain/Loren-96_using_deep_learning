{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESN code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyjRs650d5qI"
      },
      "source": [
        "**This is the code of RC-ESN to conduct prediction on the multi-scale Lorenz 96.The two components of the RC-ESN are an input-to-reservoir\n",
        "layer with weight matrix Win, and a reservoir-to-output layer with weight matrix Wout.  A and Win are chosen randomly and are fixed i.e., they do not change during training or testing. During training, only the\n",
        "weights of the output-to-reservoir layer (Wout) are updated.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSkEXdwz40MP"
      },
      "source": [
        "#importing all the required libraries.\n",
        "import numpy as np\n",
        "import scipy.sparse as sparse\n",
        "from scipy.sparse import linalg\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hw4GFJ541X0"
      },
      "source": [
        "#Defining the global variables\n",
        "#This will change the initial condition used. Currently it starts from the first value\n",
        "shift_k = 0\n",
        "\n",
        "approx_res_size = 5000\n",
        "\n",
        "#model parameters\n",
        "model_params = {'tau': 0.25,      \n",
        "                'nstep': 1000,\n",
        "                'N': 8,\n",
        "                'd': 22}\n",
        "\n",
        "#reservior parameters\n",
        "res_params = {'radius':0.1,\n",
        "             'degree': 3,\n",
        "             'sigma': 0.5,\n",
        "             'train_length': 100000,\n",
        "             'N': int(np.floor(approx_res_size/model_params['N']) * model_params['N']),\n",
        "             'num_inputs': model_params['N'],\n",
        "             'predict_length': 10000,\n",
        "             'beta': 0.0001\n",
        "              }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwlyS_im4-0L"
      },
      "source": [
        "# The ESN functions for training\n",
        "\n",
        "#Generating Reservoir A such data spectral radius as to be less than unity\n",
        "def generate_reservoir(size,radius,degree):\n",
        "    sparsity = degree/float(size);\n",
        "    A = sparse.rand(size,size,density=sparsity).todense()             #sparsely connected neurons\n",
        "    vals = np.linalg.eigvals(A)\n",
        "    e = np.max(np.abs(vals))                                          # e is largest eigen value\n",
        "    A = (A/e) * radius                                                \n",
        "    return A\n",
        "\n",
        "#Computing state matrix of reservoir layer\n",
        "def reservoir_layer(A, Win, input, res_params):\n",
        "    states = np.zeros((res_params['N'],res_params['train_length']))   \n",
        "    for i in range(res_params['train_length']-1):\n",
        "        states[:,i+1] = np.tanh(np.dot(A,states[:,i]) + np.dot(Win,input[:,i])) #states are calculated using r(t + âˆ†t) = tanh (Ar(t) + WinX(t))\n",
        "    return states\n",
        "\n",
        "#training the reservoir\n",
        "def train_reservoir(res_params, data):\n",
        "    A = generate_reservoir(res_params['N'], res_params['radius'], res_params['degree'])   #calling generate_reservoir function\n",
        "    q = int(res_params['N']/res_params['num_inputs'])                                     #No. of neuron in a layer of reservoir\n",
        "    Win = np.zeros((res_params['N'],res_params['num_inputs']))\n",
        "    for i in range(res_params['num_inputs']):\n",
        "        np.random.seed(seed=i)\n",
        "        Win[i*q: (i+1)*q,i] = res_params['sigma'] * (-1 + 2 * np.random.rand(1,q)[0])    #weight matrix win whose values are drawn from a uniform random distribution on[-1,1]\n",
        "        \n",
        "    states = reservoir_layer(A, Win, data, res_params)                                  #calling reservoir_layer function\n",
        "    Wout = train(res_params, states, data)                                              #calling train function\n",
        "    x = states[:,-1]\n",
        "    return x, Wout, A, Win\n",
        "\n",
        "\n",
        "#Computing trainable matrix Wout\n",
        "def train(res_params,states,data):\n",
        "    beta = res_params['beta']\n",
        "    idenmat = beta * sparse.identity(res_params['N'])    #*\n",
        "    states2 = states.copy()\n",
        "\n",
        "    #nonlinear combinations of the columns of the reservoir state matrix using algorithm T2\n",
        "    for j in range(2,np.shape(states2)[0]-2):                           \n",
        "        if (np.mod(j,2)==0):\n",
        "            states2[j,:] = (states[j-1,:]*states[j-2,:]).copy()            # using Algorithm T2 ,if j > 1 is odd\n",
        "    U = np.dot(states2,states2.transpose()) + idenmat                      #\n",
        "    Uinv = np.linalg.inv(U)                                                \n",
        "    Wout = np.dot(Uinv,np.dot(states2,data.transpose()))                   \n",
        "    return Wout.transpose()                                               #reservior-to-output layer weight matrix wout\n",
        "\n",
        "\n",
        "#Wout is marching forward in time during prediction(testing)\n",
        "def predict(A, Win, res_params, x, Wout):\n",
        "    output = np.zeros((res_params['num_inputs'],res_params['predict_length']))\n",
        "    for i in range(res_params['predict_length']):\n",
        "        x_aug = x.copy()\n",
        "        for j in range(2,np.shape(x_aug)[0]-2):\n",
        "            if (np.mod(j,2)==0):                                          #using Algorithm T2 ,if j > 1 is odd\n",
        "                x_aug[j] = (x[j-1]*x[j-2]).copy()\n",
        "        out = np.squeeze(np.asarray(np.dot(Wout,x_aug)))                  #using prediction process equation\n",
        "        output[:,i] = out\n",
        "        x1 = np.tanh(np.dot(A,x) + np.dot(Win,out))                       #states are getting calculated for further prediction\n",
        "        x = np.squeeze(np.asarray(x1))\n",
        "    return output, x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoJLnYtD5U1v"
      },
      "source": [
        "#loading Lorenz data\n",
        "dataf = pd.read_csv(\"lorenz_data.csv\",header=None)\n",
        "data = np.transpose(np.array(dataf))\n",
        "\n",
        "# Train reservoir\n",
        "x,Wout,A,Win = train_reservoir(res_params,data[:,shift_k:shift_k+res_params['train_length']])\n",
        "\n",
        "# Prediction\n",
        "output, _ = predict(A, Win,res_params,x,Wout)\n",
        "np.save('Expansion_2step_back'+'R_size_train_'+str(res_params['train_length'])+'_Rd_'+str(res_params['radius'])+'_Shift_'+str(shift_k)+'.npy',output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu4h3saW5_qg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}